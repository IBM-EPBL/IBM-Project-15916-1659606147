{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Keras libraries"
      ],
      "metadata": {
        "id": "MSQAwDy2zBLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "dGjMFRWVzLR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing ImageDataGenerator from Keras"
      ],
      "metadata": {
        "id": "VSOVZux818Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "mpfbwXSFzZ-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Parameters"
      ],
      "metadata": {
        "id": "zvk5hwOM2LGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=ImageDataGenerator(rescale=1./255,\n",
        "                                 shear_range=0.2,\n",
        "                                 rotation_range=180,\n",
        "                                 zoom_range=0.2,\n",
        "                                 horizontal_flip=True)\n",
        "train = ImageDataGenerator(rescale=1/255)\n",
        "test = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "DalRAnYYzgxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ImageDataGenerator functionality to train dataset\n"
      ],
      "metadata": {
        "id": "NNjhmtg22XTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train.flow_from_directory(\"/content/drive/MyDrive/forest fire/Dataset/Dataset/train_set\",\n",
        "                                          target_size=(64,64),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode = 'binary' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ii79SEUz6-W",
        "outputId": "78052d3c-0bd0-49a2-8715-153166bd7a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 441 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ImageDataGenerator functionality to test dataset"
      ],
      "metadata": {
        "id": "nxxP9Vjp28Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test.flow_from_directory(\"/content/drive/MyDrive/forest fire/Dataset/Dataset/test_set\",\n",
        "                                          target_size=(64,64),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode = 'binary' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-ZOBAxd0QE5",
        "outputId": "c575555c-034d-45a9-8339-1c8c3562cafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 121 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTLfKBL70dSg",
        "outputId": "f7bab706-50f1-4d91-9c4e-df6343f64888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'forest': 0, 'with fire': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NbW7fHa0e9x",
        "outputId": "e4748f31-f84f-47ce-e01e-56e83a443ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'forest': 0, 'with fire': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Model Building Libraries\n"
      ],
      "metadata": {
        "id": "XF57gVO53EjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to define the linear Initialisation import sequential\n",
        "from keras.models import Sequential\n",
        "#to add layers import Dense\n",
        "from keras.layers import Dense\n",
        "#to create Convolutional kernel import convolution2D\n",
        "from keras.layers import Convolution2D\n",
        "#import Maxpooling layer \n",
        "from keras.layers import MaxPooling2D\n",
        "#import flatten layer\n",
        "from keras.layers import Flatten\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hoR3P5d30jFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing the model"
      ],
      "metadata": {
        "id": "tEQ7kNUy3KAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =Sequential()"
      ],
      "metadata": {
        "id": "HuWI_PFs0vLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding CNN Layers"
      ],
      "metadata": {
        "id": "Hgs-5Rwf3MLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
        "#add maxpooling layers\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#add faltten layer\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "nTrlqK3O00EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Dense layers"
      ],
      "metadata": {
        "id": "BMDoCFHL3QbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add hidden layers\n",
        "model.add(Dense(150,activation='relu'))\n",
        "#add output layer\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_hgk8Jhr07eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "configuring the learning process"
      ],
      "metadata": {
        "id": "X23ZIJY93WHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "MhicZSj50-wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "lghd-Pal3i7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=14,epochs=5,validation_data=x_test,validation_steps=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okrbw_Gr1EMU",
        "outputId": "13a8ed5d-0195-4edc-ad56-08f971182bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.9393 - accuracy: 0.7052"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/14 [==============================] - 159s 11s/step - loss: 0.9393 - accuracy: 0.7052 - val_loss: 0.2211 - val_accuracy: 0.9008\n",
            "Epoch 2/5\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.3004 - accuracy: 0.8707\n",
            "Epoch 3/5\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.1978 - accuracy: 0.9116\n",
            "Epoch 4/5\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.1572 - accuracy: 0.9320\n",
            "Epoch 5/5\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.1253 - accuracy: 0.9478\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7facb7c17f90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Save The Model"
      ],
      "metadata": {
        "id": "UdRyNlVN4F9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"forest1.h5\")"
      ],
      "metadata": {
        "id": "1-y8cmb24Iww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions"
      ],
      "metadata": {
        "id": "daobk_O-5JOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "predictions = np.round(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDPD8LIN5L-9",
        "outputId": "59804384-375b-4e7f-fc49-7e7b99aac77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0RaszpH5Tq8",
        "outputId": "b6637074-3bde-45a3-afd1-7db497cf16f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Er0_fL5d4U",
        "outputId": "7cf210af-05bd-45b4-ac71-5ba517e953e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import load_model from keras.model\n",
        "from keras.models import load_model\n",
        "#import image class from keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import cv2"
      ],
      "metadata": {
        "id": "-vPGVjm-5iMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved model\n",
        "model = load_model(\"forest1.h5\")"
      ],
      "metadata": {
        "id": "g_7EUgeJ5ok7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictImage(filename):\n",
        "  img1 = image.load_img(filename,target_size=(64,64))\n",
        "  Y = image.img_to_array(img1)\n",
        "  X = np.expand_dims(Y,axis=0)\n",
        "  val = model.predict(X)\n",
        "  print(val)\n",
        "  if val == 1:\n",
        "    print(\" fire\")\n",
        "  elif val == 0:\n",
        "      print(\"no fire\")"
      ],
      "metadata": {
        "id": "dYOZSpOd52Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictImage(\"/content/drive/MyDrive/forest fire/Dataset/Dataset/test_set/with fire/FORESTFIRE (1).jpg\")"
      ],
      "metadata": {
        "id": "exXlehDu5--F",
        "outputId": "6a1af1ba-51ec-4348-d194-f5c3e8a5c7ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "[[1.]]\n",
            " fire\n"
          ]
        }
      ]
    }
  ]
}